# Model Merging Repository
This repository is dedicated to studying and organizing information about Model Merging.

# Model Merging Papers

## Loss Landscapes & Mode Connectivity

[Qualitatively characterizing neural network optimization problems (ICLR 2015)](https://arxiv.org/abs/1412.6544)

[Linear Mode Connectivity and the Lottery Ticket Hypothesis (ICML 2020)](https://arxiv.org/abs/1912.05671)

[Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs (NIPS 2018)](https://arxiv.org/abs/1802.10026)

[The Role of Permutation Invariance in Linear Mode Connectivity of Neural Networks (ICLR 2024)](https://arxiv.org/abs/2110.06296)

[Essentially No Barriers in Neural Network Energy Landscape (ICML 2018)](https://arxiv.org/abs/1803.00885)

[Averaging Weights Leads to Wider Optima and Better Generalization (UAI 2018)](https://arxiv.org/abs/1803.05407)

## Model Merging techniques

[Merging Models with Fisher-Weighted Averaging (NeurIPS 2022)](https://arxiv.org/abs/2111.09832)

[Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time (ICML 2022)](https://arxiv.org/abs/2203.05482)

[Git Re-Basin: Merging Models modulo Permutation Symmetries (ICLR 2023)](https://arxiv.org/abs/2209.04836)

[Editing Models with Task Arithmetic (ICLR 2023)](https://arxiv.org/abs/2212.04089)

[TIES-Merging: Resolving Interference When Merging Models (NeurIPS 2023)](https://arxiv.org/abs/2306.01708)

[AdaMerging: Adaptive Model Merging for Multi-Task Learning (ICLR 2024)](https://arxiv.org/abs/2310.02575)

[Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch (ICML 2024)](https://arxiv.org/abs/2311.03099)

[Model Merging by Uncertainty-Based Gradient Matching (ICLR 2024)](https://arxiv.org/abs/2310.12808)
